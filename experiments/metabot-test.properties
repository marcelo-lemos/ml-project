# specifies the portfolio members

portfolio.members = WorkerRush, LightRush, RangedRush, HeavyRush, Expand, BuildBarracks

### the parameters below are related to the reinforcement learning algorithm ###
# specifies the type of learning agent
rl.agent = "sarsa"

# the initial value and decay of exploration rate (epsilon is multiplied by this decay factor after each episode)
rl.epsilon.initial = 0
rl.epsilon.decay = 1

# the initial value and decay of learning rate (alpha is multiplied by this decay factor after each episode)
rl.alpha.initial = 0
rl.alpha.decay = 1


# the discount factor
rl.gamma = 1

# the eligibility trace (not used yet)
rl.lambda = 0

# the feature extractor
rl.feature.extractor = quadrant_model

# the map is divided in quadrant_division x quadrant_division quadrants
# this parameter is specific of the quadrant_model
rl.feature.extractor.quadrant_division = 3

output.choices_prefix = test_choices/match
output.qvalues_prefix = test_qvalues/match

rl.sticky_actions = 100